{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "number_classes = 7 \n",
    "rows=48\n",
    "cols=48\n",
    "batch_size = 16\n",
    "\n",
    "train_data_direction = './dataset/train'\n",
    "test_data_direction = './dataset/test'\n",
    "\n",
    "#Using Data Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  rotation_range=30,\n",
    "                                  shear_range=0.3,\n",
    "                                  zoom_range=0.3,\n",
    "                                  width_shift_range=0.4,\n",
    "                                  height_shift_range=0.4,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_direction,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = (rows , cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_direction,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = (rows , cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import ELU\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_initializer='he_normal', input_shape=(rows,cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_initializer='he_normal', input_shape=(rows,cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#Softmax Activation in Output\n",
    "model.add(Dense(number_classes, kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./checkpoint/emotion_model.h5\",\n",
    "                            monitor=\"val_loss\",\n",
    "                            mode=\"min\",\n",
    "                            save_best_only=True,\n",
    "                            verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                         min_delta = 0,\n",
    "                         patience = 10,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights = True)\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor=0.2, patience=3, verbose=1, min_delta=0.0001)\n",
    "\n",
    "#Create callback list\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = Adam(lr=0.001),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "total_train_samples = train_generator.samples\n",
    "total_test_samples = test_generator.samples\n",
    "epochs = 40\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=total_train_samples // batch_size,\n",
    "            epochs = epochs,\n",
    "            callbacks = callbacks,\n",
    "            validation_data = test_generator,\n",
    "            validation_steps = total_test_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Resume Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1794/1794 [==============================] - ETA: 0s - loss: 1.1821 - accuracy: 0.5651\n",
      "Epoch 00001: val_loss improved from inf to 0.97026, saving model to ./checkpoint\\emotion_model.h5\n",
      "1794/1794 [==============================] - 98s 55ms/step - loss: 1.1821 - accuracy: 0.5651 - val_loss: 0.9703 - val_accuracy: 0.6387\n",
      "Epoch 2/40\n",
      "1793/1794 [============================>.] - ETA: 0s - loss: 1.1877 - accuracy: 0.5647\n",
      "Epoch 00002: val_loss did not improve from 0.97026\n",
      "1794/1794 [==============================] - 55s 31ms/step - loss: 1.1876 - accuracy: 0.5647 - val_loss: 0.9759 - val_accuracy: 0.6363\n",
      "Epoch 3/40\n",
      "1793/1794 [============================>.] - ETA: 0s - loss: 1.1830 - accuracy: 0.5642\n",
      "Epoch 00003: val_loss did not improve from 0.97026\n",
      "1794/1794 [==============================] - 53s 30ms/step - loss: 1.1833 - accuracy: 0.5641 - val_loss: 1.0081 - val_accuracy: 0.6251\n",
      "Epoch 4/40\n",
      "1793/1794 [============================>.] - ETA: 0s - loss: 1.1914 - accuracy: 0.5622\n",
      "Epoch 00004: val_loss did not improve from 0.97026\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "1794/1794 [==============================] - 40s 22ms/step - loss: 1.1914 - accuracy: 0.5622 - val_loss: 0.9811 - val_accuracy: 0.6366\n",
      "Epoch 5/40\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 1.1776 - accuracy: 0.5691\n",
      "Epoch 00005: val_loss improved from 0.97026 to 0.95533, saving model to ./checkpoint\\emotion_model.h5\n",
      "1794/1794 [==============================] - 38s 21ms/step - loss: 1.1776 - accuracy: 0.5691 - val_loss: 0.9553 - val_accuracy: 0.6444\n",
      "Epoch 6/40\n",
      "1793/1794 [============================>.] - ETA: 0s - loss: 1.1694 - accuracy: 0.5715\n",
      "Epoch 00006: val_loss did not improve from 0.95533\n",
      "1794/1794 [==============================] - 34s 19ms/step - loss: 1.1695 - accuracy: 0.5715 - val_loss: 0.9592 - val_accuracy: 0.6427\n",
      "Epoch 7/40\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 1.1560 - accuracy: 0.5757 ETA: 0s - loss: 1.1562 - accuracy: 0.\n",
      "Epoch 00007: val_loss improved from 0.95533 to 0.95086, saving model to ./checkpoint\\emotion_model.h5\n",
      "1794/1794 [==============================] - 36s 20ms/step - loss: 1.1560 - accuracy: 0.5757 - val_loss: 0.9509 - val_accuracy: 0.6494\n",
      "Epoch 8/40\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 1.1486 - accuracy: 0.5823\n",
      "Epoch 00008: val_loss did not improve from 0.95086\n",
      "1794/1794 [==============================] - 37s 21ms/step - loss: 1.1486 - accuracy: 0.5823 - val_loss: 0.9521 - val_accuracy: 0.6477\n",
      "Epoch 9/40\n",
      "1792/1794 [============================>.] - ETA: 0s - loss: 1.1486 - accuracy: 0.5789 ETA: 0s - loss: 1.1490 - accura\n",
      "Epoch 00009: val_loss improved from 0.95086 to 0.94354, saving model to ./checkpoint\\emotion_model.h5\n",
      "1794/1794 [==============================] - 54s 30ms/step - loss: 1.1488 - accuracy: 0.5787 - val_loss: 0.9435 - val_accuracy: 0.6468\n",
      "Epoch 10/40\n",
      "1793/1794 [============================>.] - ETA: 0s - loss: 1.1513 - accuracy: 0.5783\n",
      "Epoch 00010: val_loss did not improve from 0.94354\n",
      "1794/1794 [==============================] - 43s 24ms/step - loss: 1.1516 - accuracy: 0.5781 - val_loss: 0.9482 - val_accuracy: 0.6479\n",
      "Epoch 11/40\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 1.1510 - accuracy: 0.5791\n",
      "Epoch 00011: val_loss did not improve from 0.94354\n",
      "1794/1794 [==============================] - 57s 32ms/step - loss: 1.1510 - accuracy: 0.5791 - val_loss: 0.9439 - val_accuracy: 0.6505\n",
      "Epoch 12/40\n",
      "1793/1794 [============================>.] - ETA: 0s - loss: 1.1515 - accuracy: 0.5782\n",
      "Epoch 00012: val_loss did not improve from 0.94354\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "1794/1794 [==============================] - 40s 22ms/step - loss: 1.1515 - accuracy: 0.5782 - val_loss: 0.9525 - val_accuracy: 0.6473\n",
      "Epoch 13/40\n",
      "1791/1794 [============================>.] - ETA: 0s - loss: 1.1470 - accuracy: 0.5815\n",
      "Epoch 00013: val_loss did not improve from 0.94354\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1473 - accuracy: 0.5814 - val_loss: 0.9463 - val_accuracy: 0.6489\n",
      "Epoch 14/40\n",
      "1789/1794 [============================>.] - ETA: 0s - loss: 1.1455 - accuracy: 0.5812\n",
      "Epoch 00014: val_loss did not improve from 0.94354\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1455 - accuracy: 0.5811 - val_loss: 0.9442 - val_accuracy: 0.6491\n",
      "Epoch 15/40\n",
      "1792/1794 [============================>.] - ETA: 0s - loss: 1.1446 - accuracy: 0.5822\n",
      "Epoch 00015: val_loss improved from 0.94354 to 0.94173, saving model to ./checkpoint\\emotion_model.h5\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1446 - accuracy: 0.5823 - val_loss: 0.9417 - val_accuracy: 0.6505\n",
      "Epoch 16/40\n",
      "1791/1794 [============================>.] - ETA: 0s - loss: 1.1442 - accuracy: 0.5859\n",
      "Epoch 00016: val_loss improved from 0.94173 to 0.94032, saving model to ./checkpoint\\emotion_model.h5\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1440 - accuracy: 0.5860 - val_loss: 0.9403 - val_accuracy: 0.6518\n",
      "Epoch 17/40\n",
      "1793/1794 [============================>.] - ETA: 0s - loss: 1.1377 - accuracy: 0.5823\n",
      "Epoch 00017: val_loss improved from 0.94032 to 0.93950, saving model to ./checkpoint\\emotion_model.h5\n",
      "1794/1794 [==============================] - 90s 50ms/step - loss: 1.1379 - accuracy: 0.5823 - val_loss: 0.9395 - val_accuracy: 0.6539\n",
      "Epoch 18/40\n",
      "1793/1794 [============================>.] - ETA: 0s - loss: 1.1422 - accuracy: 0.5814\n",
      "Epoch 00018: val_loss did not improve from 0.93950\n",
      "1794/1794 [==============================] - 26s 15ms/step - loss: 1.1420 - accuracy: 0.5814 - val_loss: 0.9406 - val_accuracy: 0.6525\n",
      "Epoch 19/40\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 1.1332 - accuracy: 0.5888\n",
      "Epoch 00019: val_loss did not improve from 0.93950\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1332 - accuracy: 0.5888 - val_loss: 0.9431 - val_accuracy: 0.6509\n",
      "Epoch 20/40\n",
      "1792/1794 [============================>.] - ETA: 0s - loss: 1.1354 - accuracy: 0.5851\n",
      "Epoch 00020: val_loss did not improve from 0.93950\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1351 - accuracy: 0.5852 - val_loss: 0.9421 - val_accuracy: 0.6512\n",
      "Epoch 21/40\n",
      "1789/1794 [============================>.] - ETA: 0s - loss: 1.1485 - accuracy: 0.5817\n",
      "Epoch 00021: val_loss did not improve from 0.93950\n",
      "1794/1794 [==============================] - 21s 11ms/step - loss: 1.1486 - accuracy: 0.5816 - val_loss: 0.9431 - val_accuracy: 0.6500\n",
      "Epoch 22/40\n",
      "1790/1794 [============================>.] - ETA: 0s - loss: 1.1408 - accuracy: 0.5841\n",
      "Epoch 00022: val_loss did not improve from 0.93950\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1408 - accuracy: 0.5839 - val_loss: 0.9416 - val_accuracy: 0.6512\n",
      "Epoch 23/40\n",
      "1791/1794 [============================>.] - ETA: 0s - loss: 1.1367 - accuracy: 0.5843\n",
      "Epoch 00023: val_loss did not improve from 0.93950\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1368 - accuracy: 0.5842 - val_loss: 0.9429 - val_accuracy: 0.6509\n",
      "Epoch 24/40\n",
      "1789/1794 [============================>.] - ETA: 0s - loss: 1.1457 - accuracy: 0.5821\n",
      "Epoch 00024: val_loss did not improve from 0.93950\n",
      "1794/1794 [==============================] - 22s 12ms/step - loss: 1.1457 - accuracy: 0.5822 - val_loss: 0.9431 - val_accuracy: 0.6522\n",
      "Epoch 25/40\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 1.1406 - accuracy: 0.5826\n",
      "Epoch 00025: val_loss did not improve from 0.93950\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1406 - accuracy: 0.5826 - val_loss: 0.9411 - val_accuracy: 0.6507\n",
      "Epoch 26/40\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 1.1315 - accuracy: 0.5858\n",
      "Epoch 00026: val_loss did not improve from 0.93950\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "1794/1794 [==============================] - 21s 11ms/step - loss: 1.1315 - accuracy: 0.5858 - val_loss: 0.9421 - val_accuracy: 0.6512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40\n",
      "1791/1794 [============================>.] - ETA: 0s - loss: 1.1390 - accuracy: 0.5814Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.93950\n",
      "1794/1794 [==============================] - 20s 11ms/step - loss: 1.1391 - accuracy: 0.5814 - val_loss: 0.9407 - val_accuracy: 0.6515\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import ELU\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "number_classes = 7 \n",
    "rows=48\n",
    "cols=48\n",
    "batch_size = 16\n",
    "\n",
    "train_data_direction = './dataset/train'\n",
    "test_data_direction = './dataset/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  rotation_range=30,\n",
    "                                  shear_range=0.3,\n",
    "                                  zoom_range=0.3,\n",
    "                                  width_shift_range=0.4,\n",
    "                                  height_shift_range=0.4,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./checkpoint/emotion_model.h5\",\n",
    "                            monitor=\"val_loss\",\n",
    "                            mode=\"min\",\n",
    "                            save_best_only=True,\n",
    "                            verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                         min_delta = 0,\n",
    "                         patience = 10,\n",
    "                         verbose=1,\n",
    "                         restore_best_weights = True)\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor=0.2, patience=3, verbose=1, min_delta=0.0001)\n",
    "\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_direction,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = (rows , cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_direction,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = (rows , cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)\n",
    "\n",
    "total_train_samples = train_generator.samples\n",
    "total_test_samples = test_generator.samples\n",
    "epochs = 40\n",
    "model = load_model('./checkpoint/emotion_model.h5')\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = Adam(lr=0.001),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=total_train_samples // batch_size,\n",
    "            epochs = epochs,\n",
    "            callbacks = callbacks,\n",
    "            validation_data = test_generator,\n",
    "            validation_steps = total_test_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "classifier = load_model('./checkpoint/emotion_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_direction,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = (rows , cols),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)\n",
    "\n",
    "class_labels = test_generator.class_indices\n",
    "class_labels = {v : k for k,v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0), np.zeros((48,48), np.uint8), img\n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        x = x-50\n",
    "        w = w+50\n",
    "        y = y-50\n",
    "        h = h+50\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h) , (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        \n",
    "    try:\n",
    "        roi_gray = cv2.resize(roi_gray, (48,48), interpolation = cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (x,w,y,h), np.zeros((48,48), np.uint8), img\n",
    "    return (x,w,y,h), roi_gray, img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    rect, face, image = face_detector(frame)\n",
    "    if np.sum([face]) != 0.0:\n",
    "        roi = face.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "        preds = classifier.predict(roi)[0]\n",
    "        label = class_labels[preds.argmax()]\n",
    "        label_position = (rect[0] + int((rect[1]/2)), rect[2] + 25)\n",
    "        cv2.putText(image, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 3)\n",
    "    else:\n",
    "        cv2.putText(image, \"No Face found\", (20,60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 3)\n",
    "        \n",
    "    cv2.imshow('Emotion Detector', image)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
